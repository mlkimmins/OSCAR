{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### optimized for python 3.8 - Pytorch and Tensorflow kernel on Azure on mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04 base docker image. Ensure right kernel"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "e87c8f4a-6ec8-4e15-a6ba-229bede853c2"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-04-24 21:58:30.195312: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-04-24 21:58:35.739062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682373522879
        }
      },
      "id": "2d554205-b48e-4224-8ee7-09baa6c11e38"
    },
    {
      "cell_type": "code",
      "source": [
        "%conda install -c conda-forge -y ipywidgets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\nSolving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \nThe environment is inconsistent, please check the package plan carefully\nThe following packages are causing the inconsistency:\n\n  - anaconda/linux-64::ipykernel==6.19.2=py38hb070fc8_0\n  - anaconda/linux-64::ipython==8.8.0=py38h06a4308_0\n\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n\n## Package Plan ##\n\n  environment location: /anaconda/envs/azureml_py38_PT_TF\n\n  added / updated specs:\n    - ipywidgets\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    openssl-1.1.1t             |       h7f8727e_0         3.7 MB\n    prompt-toolkit-3.0.38      |     pyha770c72_0         263 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         4.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n  ipywidgets         conda-forge/noarch::ipywidgets-8.0.6-pyhd8ed1ab_0 \n  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-3.0.7-pyhd8ed1ab_0 \n  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.38-pyha770c72_0 \n  widgetsnbextension conda-forge/noarch::widgetsnbextension-4.0.7-pyhd8ed1ab_0 \n\nThe following packages will be UPDATED:\n\n  openssl               anaconda::openssl-1.1.1s-h7f8727e_0 --> pkgs/main::openssl-1.1.1t-h7f8727e_0 \n\nThe following packages will be SUPERSEDED by a higher-priority channel:\n\n  ca-certificates    anaconda::ca-certificates-2023.01.10-~ --> conda-forge::ca-certificates-2022.12.7-ha878542_0 \n  certifi            anaconda/linux-64::certifi-2022.12.7-~ --> conda-forge/noarch::certifi-2022.12.7-pyhd8ed1ab_0 \n\n\n\nDownloading and Extracting Packages\nopenssl-1.1.1t       | 3.7 MB    |                                       |   0% \nopenssl-1.1.1t       | 3.7 MB    | ##################################### | 100% \u001b[A\nprompt-toolkit-3.0.3 | 263 KB    | ##2                                   |   6% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\nPreparing transaction: / \b\bdone\nVerifying transaction: \\ \b\b| \b\b/ \b\bdone\nExecuting transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682373564392
        }
      },
      "id": "a5154706-e6ba-45fa-be53-ace0e88f08c8"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rouge-score"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting rouge-score\n  Using cached rouge_score-0.1.2-py3-none-any.whl\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from rouge-score) (1.23.5)\nRequirement already satisfied: six>=1.14.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: absl-py in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from rouge-score) (1.4.0)\nCollecting nltk\n  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nltk->rouge-score) (4.65.0)\nRequirement already satisfied: click in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nltk->rouge-score) (8.1.3)\nCollecting regex>=2021.8.3\n  Using cached regex-2023.3.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nltk->rouge-score) (1.2.0)\nInstalling collected packages: regex, nltk, rouge-score\nSuccessfully installed nltk-3.8.1 regex-2023.3.23 rouge-score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "c78e924f-50ad-443a-afcb-fe3ca7483b1b"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pip install transformers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: pip in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (22.3.1)\nCollecting install\n  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\nCollecting transformers\n  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (22.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from transformers) (0.14.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\nInstalling collected packages: tokenizers, install, transformers\nSuccessfully installed install-1.3.5 tokenizers-0.13.3 transformers-4.28.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "000b5053-ebdd-4c3b-9a0d-d21c920aa891"
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install tensorflow_addons"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting tensorflow_addons\n  Downloading tensorflow_addons-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typeguard<3.0.0,>=2.7\n  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from tensorflow_addons) (22.0)\nInstalling collected packages: typeguard, tensorflow_addons\nSuccessfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "2a12e51b-53bf-4ff0-998a-fb8017ed1e85"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting datasets\n  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (22.0)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (2.0.0)\nCollecting aiohttp\n  Downloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (9.0.0)\nRequirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (4.65.0)\nCollecting fsspec[http]>=2021.11.1\n  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (2.28.2)\nCollecting dill<0.3.7,>=0.3.0\n  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting multiprocess\n  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (1.23.5)\nCollecting xxhash\n  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from datasets) (6.0)\nCollecting responses<0.19\n  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\nCollecting aiosignal>=1.1.2\n  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\nCollecting frozenlist>=1.1.1\n  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting multidict<7.0,>=4.5\n  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets) (22.2.0)\nCollecting yarl<2.0,>=1.0\n  Downloading yarl-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\nCollecting filelock\n  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas->datasets) (2022.7.1)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nInstalling collected packages: xxhash, multidict, fsspec, frozenlist, filelock, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\nSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 filelock-3.12.0 frozenlist-1.3.3 fsspec-2023.4.0 huggingface-hub-0.14.0 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "78d8ba51-c5d8-4958-b9cf-1d36cf0b5500"
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install tensorflow_hub\n",
        "# %pip install tf_keras_vis"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "3c220cf2-5ae1-4f9e-98a3-f879334d89df"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682374232675
        }
      },
      "id": "9651c12d-e510-4450-97d5-8f3a06c7ae3f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment configuration finished"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "6aa30d68-6cc4-408a-9b1e-6920a40a886b"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n\r\n"
        }
      ],
      "execution_count": 10,
      "metadata": {},
      "id": "08f6df85"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1682373725894
        }
      },
      "id": "6f6c11bb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset"
      ],
      "metadata": {},
      "id": "b1a14cc5"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset(\"scientific_papers\", \"pubmed\", split=\"train\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/5.35k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f27548b9787549aca33d542e9b7a331d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/4.99k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69e53bb954e9403fbf93d23970424c09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/8.27k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8213dd4862d44fac8d9866f075f45a1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading and preparing dataset scientific_papers/pubmed to /home/azureuser/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f...\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1be46b3c6284e63bb3a837b84e2874d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/3.62G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94b7253c09a147fc86cc150caf96f67f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/880M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f94a513ab022493a981ddaa5bd5f0297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8cfb037d5444629952a420dddd3065b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/119924 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9c999cb014a4da8ae7b6228588db2c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/6633 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b26c3a0d43794a9ab963089f1f893867"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/6658 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f348dcf1d1b44754901be10fe808518b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset scientific_papers downloaded and prepared to /home/azureuser/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/306757013fb6f37089b6a75469e6638a553bd9f009484938d8f75a4c5e84206f. Subsequent calls will reuse this data.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1682374046144
        }
      },
      "id": "97087531"
    },
    {
      "cell_type": "code",
      "source": [
        "# val_dataset = load_dataset(\"scientific_papers\", \"pubmed\", split=\"validation\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "33318445"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### show random downloaded text"
      ],
      "metadata": {},
      "id": "42121b27"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682374136183
        }
      },
      "id": "5955b545"
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_dataset)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Dataset({\n    features: ['article', 'abstract', 'section_names'],\n    num_rows: 119924\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1682374243357
        }
      },
      "id": "53a64822"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility functions we wrote are defined in oscar_utils.py for version control. Please DO NOT edit them on the fly here. any edits and addition to a Class or method defined must be added to oscar_utils.py"
      ],
      "metadata": {},
      "id": "db496145"
    },
    {
      "cell_type": "code",
      "source": [
        "# from oscar_utils import show_random_elements"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {},
      "id": "7ab9c4c7"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_elements(dataset, num_examples=4):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))\n",
        "    return df\n"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1682374336330
        }
      },
      "id": "a4bb916a"
    },
    {
      "cell_type": "code",
      "source": [
        "random_df = show_random_elements(train_dataset, 1)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>abstract</th>\n      <th>section_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the average human life expectancy has been progressively prolonged over the last few decades , with a consequent rise in the prevalence of chronic degenerative disorders , one of which is dementia .\\nit has been estimated that , in 2010 , there were 35.6 million patients suffering from some form of dementia , worldwide .\\ntherefore , it is expected to reach 65.7 million in 2030 and 115.4 million by 2050.1 individuals suffering from dementia are affected by a progressive and significant global deterioration and , consequently , might require longer assistance in the advanced stage of the illness.2,3 the person who takes care of a patient with dementia is known as a caregiver ; in most cases , the caregiver is a family member.4 assisting a person affected by cognitive disorders can drain the emotional resources of any individual so much that the caregiver is often defined as  the hidden patient  due to the not unlikely possibility of developing mental and physical symptoms .\\nin fact , caregivers end up dedicating less time to their own needs and to other family and professional roles , thus neglecting their own personal health and social life.5,6 alzheimer s disease ( ad ) and other related dementias are public health priorities in the european union because of their prevalence , cost , and profound impact on society . nineteen participating countries of the european union created the joint action alzheimer cooperative valuation in europe ( alcove ) to share knowledge about dementia to preserve the health , quality of life , autonomy , and dignity of people living with dementia and their carers.7 the impact of the illness on the caregiver is defined as burden , a term that expresses the comprehensive effect on the caregiver s global needs in the course of looking after the patient ( ie , physical , psychological , and social ) .\\nnumerous studies have noted that the problems that mainly affect the caregiver range from simple physical fatigue , problems with the family and at work , feelings of incapacity and inadequacy , sleeping difficulties , depression , and anxiety.8,9 in other cases , the depressed caregiver can be affected by the onset of more complex pathologies , such as arterial hypertension and gastrointestinal pathologies.10 others have reported that caregiving per se does not always lead to mental or physical impairment.11 this study aims to analyze the presence and relationship between specific sociodemographic variables , the subjective burden , and depressive symptoms among caregivers of patients with dementia .\\na total of 150 caregivers of patients under treatment at the unit operativa tutela anziani in catanzaro ( southern italy ) were consecutively recruited for this study .\\nunit operativa tutela anziani is a health care unit for the elderly , specialized in the diagnosis and care of dementia .\\ninclusion criteria of our study were spouses , next of kin , and other close family members of patients who scored 2 on the clinical dementia rating scale.12 physicians with adequate and specific training in this field of research interviewed the participants .\\ndata were collected for the following variables : demographics ( sex , age , kinship to the patient , civil state , education , socioeconomic level [ average annual income ] ) , occupation , perceived state of health , level of urbanity ( high densely populated area : &gt; 500 inhabitants / km or total population &gt; 50,000 inhabitants ; middle densely populated area : &gt; 100 inhabitants / km or total population &gt; 50,000 inhabitants ; low densely populated area : &lt; 100 inhabitants / km or total population &gt; 50,000 ) , cohabitation with the patient , attendance in family support groups , type and entity of the subjective burden and , therefore , the stress in relation to assisting the patient , and the presence of contingent depressive symptoms . the interviews with the caregivers were conducted in a separate room during the time when the patients were visited by their neurologists .\\nthe evaluation of the caregivers burden was assessed by means of the caregiver burden inventory ( cbi).13,14 it is an easy - to - administer tool to evaluate the burden of caregivers of patients with ad and correlated dementia in multifaceted dimensions : objective , psychological , physical , social , and emotional .\\nthis self - report tool must be compiled by the main caregiver , who is asked to identify the answer most closely matching his or her own conditions or personal impressions .\\nthe objective burden , or time - dependence , describes the burden associated with time restriction for the caregiver and relates to time required for patient assistance ( items 15 ) ; the developmental burden ( items 610 ) describes the caregiver s perception of isolation compared with his peers ; the physical burden ( items 1114 ) describes the feelings of chronic fatigue and somatic health problems ; the social burden ( items 1519 ) explains role conflicts ; and the emotional burden ( items 2024 ) describes feelings toward the patient s behavior .\\nfive items account for each dimension , except for the physical burden , which is composed of four items , in a likert - type scale of 04 .\\nthe total score ranges from 0 to 100 ; scores for each dimension increase proportionally with the severity of the burden perceived by the caregiver .\\nprofiles are used to build ad hoc psychosocial interventions.15 a total cbi score between 24 and 36 indicates a need to seek some form of respite care , whereas a total cbi score &gt; 36 indicates a risk of burnout .\\nequal total scores may relay very different profiles of burden , depending on the score of each dimension .\\ndepressive symptoms were assessed using the self - rating depression scale ( sds).16 this well - validated scale consists of 20 likert - type items ( 04 ) .\\nit is composed of 20 items investigating concomitant psychological and physiological depressive symptoms ( depressed mood , morning symptoms , crying , insomnia , diminished appetite , weight loss , sexual interest , constipation , palpitations , fatigue , clouded reasoning , difficulty with completing tasks , difficulty with decision making , restlessness , lack of hope , irritability , diminished self - esteem , life satisfaction , suicidal ideation , and anhedonia ) .\\nanswers are rated with a four - point likert scale : rarely , sometimes , often , and almost always .\\nthe total score allows to evaluate the intensity of depressive symptoms in the last week .\\ntotal sds scores in the ranges of 2049 , 5059 , 6069 , or &gt; 70 indicate normal mood , mild depression , moderate , and severe depression , respectively .\\nall the participants were given full information about the goals and the methods of the research ; they were also informed that their participation was voluntary and anonymous .\\nthe study , which was conducted over a period of 6 months , from june 2010 until november 2010 , was approved by the local committee for ethics and research .\\ndata were analyzed using spss 21.0 and presented as means , standard deviations , frequencies , and percentages ( % ) .\\nunivariate analyses included t - test and chi - square test for the comparison of numerical and categorical variables , respectively .\\ncohen s effect sizes were calculated for all significant findings ; values ( negative or positive ) of 0.2 , 0.6 , 1.2 , and &gt; 1.2 indicated trivial , small , moderate , and large effect sizes , respectively.17 multivariate analysis consisted of forward , stepwise multiple linear regression techniques to assess possible associations between depression ( dependent variable ) and cbi dimensions and sociodemographic characteristics as independent variables .\\nalpha level for variables entering the logistic regression model was set at 0.2 , and alpha level for removal was set at 0.4 .\\na total of 150 caregivers of patients under treatment at the unit operativa tutela anziani in catanzaro ( southern italy ) were consecutively recruited for this study .\\nunit operativa tutela anziani is a health care unit for the elderly , specialized in the diagnosis and care of dementia .\\ninclusion criteria of our study were spouses , next of kin , and other close family members of patients who scored 2 on the clinical dementia rating scale.12\\ndata were collected for the following variables : demographics ( sex , age , kinship to the patient , civil state , education , socioeconomic level [ average annual income ] ) , occupation , perceived state of health , level of urbanity ( high densely populated area : &gt; 500 inhabitants / km or total population &gt; 50,000 inhabitants ; middle densely populated area : &gt; 100 inhabitants / km or total population &gt; 50,000 inhabitants ; low densely populated area : &lt; 100 inhabitants / km or total population &gt; 50,000 ) , cohabitation with the patient , attendance in family support groups , type and entity of the subjective burden and , therefore , the stress in relation to assisting the patient , and the presence of contingent depressive symptoms .\\nthe interviews with the caregivers were conducted in a separate room during the time when the patients were visited by their neurologists .\\nthe evaluation of the caregivers burden was assessed by means of the caregiver burden inventory ( cbi).13,14 it is an easy - to - administer tool to evaluate the burden of caregivers of patients with ad and correlated dementia in multifaceted dimensions : objective , psychological , physical , social , and emotional .\\nthis self - report tool must be compiled by the main caregiver , who is asked to identify the answer most closely matching his or her own conditions or personal impressions .\\nthe objective burden , or time - dependence , describes the burden associated with time restriction for the caregiver and relates to time required for patient assistance ( items 15 ) ; the developmental burden ( items 610 ) describes the caregiver s perception of isolation compared with his peers ; the physical burden ( items 1114 ) describes the feelings of chronic fatigue and somatic health problems ; the social burden ( items 1519 ) explains role conflicts ; and the emotional burden ( items 2024 ) describes feelings toward the patient s behavior .\\nfive items account for each dimension , except for the physical burden , which is composed of four items , in a likert - type scale of 04 .\\nthe total score ranges from 0 to 100 ; scores for each dimension increase proportionally with the severity of the burden perceived by the caregiver .\\nprofiles are used to build ad hoc psychosocial interventions.15 a total cbi score between 24 and 36 indicates a need to seek some form of respite care , whereas a total cbi score &gt; 36 indicates a risk of burnout .\\nequal total scores may relay very different profiles of burden , depending on the score of each dimension .\\ndepressive symptoms were assessed using the self - rating depression scale ( sds).16 this well - validated scale consists of 20 likert - type items ( 04 ) .\\nit is composed of 20 items investigating concomitant psychological and physiological depressive symptoms ( depressed mood , morning symptoms , crying , insomnia , diminished appetite , weight loss , sexual interest , constipation , palpitations , fatigue , clouded reasoning , difficulty with completing tasks , difficulty with decision making , restlessness , lack of hope , irritability , diminished self - esteem , life satisfaction , suicidal ideation , and anhedonia ) .\\nanswers are rated with a four - point likert scale : rarely , sometimes , often , and almost always .\\nthe total score allows to evaluate the intensity of depressive symptoms in the last week .\\ntotal sds scores in the ranges of 2049 , 5059 , 6069 , or &gt; 70 indicate normal mood , mild depression , moderate , and severe depression , respectively .\\nall the participants were given full information about the goals and the methods of the research ; they were also informed that their participation was voluntary and anonymous .\\nthe study , which was conducted over a period of 6 months , from june 2010 until november 2010 , was approved by the local committee for ethics and research .\\ndata were analyzed using spss 21.0 and presented as means , standard deviations , frequencies , and percentages ( % ) .\\nunivariate analyses included t - test and chi - square test for the comparison of numerical and categorical variables , respectively .\\ncohen s effect sizes were calculated for all significant findings ; values ( negative or positive ) of 0.2 , 0.6 , 1.2 , and &gt; 1.2 indicated trivial , small , moderate , and large effect sizes , respectively.17 multivariate analysis consisted of forward , stepwise multiple linear regression techniques to assess possible associations between depression ( dependent variable ) and cbi dimensions and sociodemographic characteristics as independent variables .\\nalpha level for variables entering the logistic regression model was set at 0.2 , and alpha level for removal was set at 0.4 .\\ntable 1 shows the sociodemographic characteristics of the sample and the results of cbi and sds by sex .\\napproximately 79% ( n=118 ) of the caregivers were women ; most of them were older than 50 years and children of the patients .\\nmost of the caregivers were married and completed education at secondary school . according to the interviews\\n, 21% ( n=31 ) of the caregivers perceived their health condition as insufficient , 40% ( n=61 ) as moderate , 36% ( n=54 ) as good , and only 3% ( n=4 ) as very good .\\nthe women described their own heath condition as worse than the men s condition ( =7.806 , p=0.05 ) .\\nninety - three percent reside in cities with more than 10,000 inhabitants , and 53% ( n=80 ) live with the patients they assist ( these data are not in the tables ) .\\nthe interviews revealed important changes in sleep , mastery , and stress that occurred in the short - term among 73 caregivers , but it was not possible to measure these changes through precise and appropriate scientific measures . with regard to cbi , 83 ( 52% )\\ncaregivers showed a total score 36 ( indicating high stress related to burden ) , of whom 72% showed pathological depression scores in sds .\\nfurthermore , only 1/3 of the caregivers who scored between 24 and 36 on the cbi scale and 7% ( n=3 ) who scored &lt; 24 had results indicating mild depression .\\nhence , an association between burden and depression was evident ( =50.545 , p&lt;0.001 ) .\\ncbi scores were similar in men and women ( t=1.031 , df=148 , p=0.304 ) .\\nno significant differences were evident between men and women ( t=1.112 , df=148 , p=0.268 ) , who showed average depression scores within the range of normal ( normal range : 54% , mildly depressed : 33% , moderately depressed : 13% ) . the results of multiple linear regression analyses are illustrated in table 2 .\\ndepression results ( adjusted r=0.622 , f=50.123 , p&lt;0.001 ) were associated with higher physical ( =0.666 , p=0.001 ) and developmental ( =0.712 , p&lt;0.001 ) burdens , lower socioeconomic status ( =4.282 , p=0.002 ) , higher level of urbanicity ( =3.070 , p=0.012 ) , and advanced age ( =2.132 , p=0.08 ) .\\npresent results give a personal and social portrait of caregivers of patients who suffer from dementia in southern italy and confirm the main results of literature in the field .\\nthere are differing opinions regarding the effects caused by the burden of dementia on caregivers .\\nthe positive value of caregiving has been emphasized in a large sample of carers taken from six european countries , as evaluated through the carers of older people in europe ( cope ) index.18 in our sample , women are overrepresented among caregivers , demonstrating that females are the principal figures of support in families.1921 according to fauth and gibbons,22 the average age of caregivers assisting patients with dementia is over 50 years , which is true for the 62% of the participants of our sample . in italy , family is the principal source of care and assistance for the needs of elderly people who are no longer self - sufficient . over half the people examined in our study\\nas outlined in other studies , caregivers are often wives / husbands , sons , or daughters who have chosen to take care of the patient at their own homes , dedicating at least three quarters of their day to the patient .\\nthis period of time tends to increase in proportion to the advancement of the illness.23 present data have shown that higher physical and developmental burdens , lower socioeconomic status , advanced age , and higher degree of urbanicity predict more severe depressive symptoms .\\npoor perceived state of health and quality of life are associated with anxious and depressive symptoms.20 close contact with a patient with dementia results in higher developmental and physical burdens for caregivers when compared with those who do not cohabit with the patient . on the other hand , a patient s functional impairment is more relevant than cognitive  behavioral alterations for the burden of the caregiver.24 with regard to the developmental burden , some studies have indicated that social isolation , among the factors , causes more impairment to caregivers mental and physical well - being.25 even at mild and moderate levels of dementia , caregivers begin to feel the repercussions that their family member s illness will have on their social life , desires , and expectations .\\ncaregivers uneasiness increases as patients conditions worsen , adding to their increasing cognitive problems , the onset of behavioral symptoms , and the consequent reduction of independence in daily life ; higher levels of anxiety are present among caregivers of patients with a long - lasting illness.26 as previously described , sociodemographic characteristics of caregivers are related to depressive symptomatology .\\nin fact , many of them ( eg , sex , socio - environmental and economic conditions , aspects of personality , and coping strategies ) influence the caregiver s experience.27,28 truzzi et al4 demonstrated in a sample of 145 caregivers of patients with dementia that an elevated level of emotional impairment leads to depressive symptomatology and demoralization.29,30 accordingly in our sample , approximately half of the caregivers showed at least mildly severe depressive symptoms . another study that analyzed 170 caregivers married to patients with dementia showed that wives had more severe depressive symptomatology than husbands;31 in fact , depression is two or three times more common among females .\\nnevertheless , our data did not show any difference either in the frequency or in the severity of depressive symptoms between the sexes .\\nhowever , our results do support that low socioeconomic status is a risk factor for depression among caregivers .\\nanother study found a threefold increased risk for experiencing high burden among caregivers of patients living in southern italy ; authors explained this result through a socioeconomic reasoning.32\\nin our sample , women are overrepresented among caregivers , demonstrating that females are the principal figures of support in families.1921 according to fauth and gibbons,22 the average age of caregivers assisting patients with dementia is over 50 years , which is true for the 62% of the participants of our sample . in italy , family is the principal source of care and assistance for the needs of elderly people who are no longer self - sufficient .\\nover half the people examined in our study were close relatives of the patients ( either son or daughter ) .\\nas outlined in other studies , caregivers are often wives / husbands , sons , or daughters who have chosen to take care of the patient at their own homes , dedicating at least three quarters of their day to the patient .\\npresent data have shown that higher physical and developmental burdens , lower socioeconomic status , advanced age , and higher degree of urbanicity predict more severe depressive symptoms .\\npoor perceived state of health and quality of life are associated with anxious and depressive symptoms.20 close contact with a patient with dementia results in higher developmental and physical burdens for caregivers when compared with those who do not cohabit with the patient . on the other hand , a patient s functional impairment is more relevant than cognitive  behavioral alterations for the burden of the caregiver.24 with regard to the developmental burden , some studies have indicated that social isolation , among the factors , causes more impairment to caregivers mental and physical well - being.25 even at mild and moderate levels of dementia , caregivers begin to feel the repercussions that their family member s illness will have on their social life , desires , and expectations .\\ncaregivers uneasiness increases as patients conditions worsen , adding to their increasing cognitive problems , the onset of behavioral symptoms , and the consequent reduction of independence in daily life ; higher levels of anxiety are present among caregivers of patients with a long - lasting illness.26 as previously described , sociodemographic characteristics of caregivers are related to depressive symptomatology .\\nin fact , many of them ( eg , sex , socio - environmental and economic conditions , aspects of personality , and coping strategies ) influence the caregiver s experience.27,28 truzzi et al4 demonstrated in a sample of 145 caregivers of patients with dementia that an elevated level of emotional impairment leads to depressive symptomatology and demoralization.29,30 accordingly in our sample , approximately half of the caregivers showed at least mildly severe depressive symptoms . another study that analyzed 170 caregivers married to patients with dementia showed that wives had more severe depressive symptomatology than husbands;31 in fact , depression is two or three times more common among females .\\nnevertheless , our data did not show any difference either in the frequency or in the severity of depressive symptoms between the sexes .\\nhowever , our results do support that low socioeconomic status is a risk factor for depression among caregivers .\\nanother study found a threefold increased risk for experiencing high burden among caregivers of patients living in southern italy ; authors explained this result through a socioeconomic reasoning.32\\nthe study was limited by the fact that the evaluations were carried out just in one center , although it is the center of patient referrals in a consumer catchment area of about 150,000 inhabitants .\\nnevertheless , the results represent the real world of a poor region in southern italy , where patients with dementia and their families find little support to cope with the illness .\\nthe patients were only given the clinical dementia rating scale to assess the severity of their condition ; other clinical and psychopathological measures might be helpful to further deepen the relationship of a patient s psychopathology and severity of dementia with the caregiver s burden .\\nour study confirms both the presence of depressive symptoms in a high percentage of caregivers of patients with dementia and the association of depression with higher burden .\\nadditionally , this study demonstrates that depressive symptoms in caregivers of patients with dementia are mainly associated with sociodemographic variables , such as advanced age , low socioeconomic status , greater urbanicity , and , to a lesser degree , physical and developmental burdens .\\nthe need for preventive support and instructive programs to help reduce the burden for caregivers of patients with dementia is the main practical implication of these results .\\nsuch interventions could help to improve their emotional state and prevent the onset of depressive symptoms .</td>\n      <td>objectiveindividuals suffering from dementia are affected by a progressive and significant global deterioration and , consequently , might require longer assistance in the advanced stage of the illness . \\n the illness is a great burden on the person who takes care of a patient , namely , the caregiver . \\n this study aims to analyze the presence and relationship of specific sociodemographic variables , subjective burden , and depressive symptoms among caregivers of patients with dementia.methodsthe participants of this study were caregivers at a health care unit for the elderly in southern italy . \\n an evaluation of the burden of patients with dementia on caregivers was carried out using the caregiver burden inventory ( cbi ) and depressive symptoms using the self - rating depression scale ( sds).resultsa total of 150 caregivers completed the study . in all , 83 ( 55% ) caregivers showed a total cbi score 36 , of whom 70% showed pathological depression scores in sds . according to sds , 28 ( 19% ) caregivers showed a total cbi score from 24 to 36 , of whom 32% were depressed . \\n depression was present in 5% of the caregivers whose cbi score was &lt; 24 . \\n hence , an association between burden and depression was evident ( 2=47.446 , p&lt;0.001 ) . a multiple linear regression analysis showed that depression ( adjusted r2=0.622 , f=50.123 , p&lt;0.001 ) was associated with higher physical ( =0.666 , p=0.001 ) and developmental ( =0.712 , p&lt;0.001 ) burdens , lower socioeconomic status ( =4.282 ; p=0.002 ) , higher level of urbanicity ( =3.070 ; p=0.012 ) , and advanced age ( =2.132 ; p=0.08).conclusionour study confirms the presence of depressive symptoms in a large number of caregivers with high burden . \\n nevertheless , this study demonstrates that depressive symptoms are mainly associated with sociodemographic variables and , to a lesser degree , physical and developmental burdens .</td>\n      <td>Introduction\\nMethods\\nParticipants\\nProcedures\\nStatistical design\\nResults\\nDiscussion\\nSociodemographic characteristics\\nBurden and other factors\\nLimitations\\nConclusion</td>\n    </tr>\n  </tbody>\n</table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1682374339075
        }
      },
      "id": "babab042"
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(random_df.to_html()))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>abstract</th>\n      <th>section_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>. n. meningitidis isolates , cerebrospinal fluid ( csf ) , and blood samples from persons with invasive disease are forwarded to the chinese centers for disease control and prevention ( cdc ) for serogroup determination by slide agglutination and/or pcr .\\nstrains are further characterized by use of pulsed - field gel electrophoresis ( pfge ) after nhei restriction enzyme digestion ( 3 ) . during february 2011june 2012\\n, we observed an increase in invasive meningococcal disease caused by n. meningitidis serogroup w in southeastern china .\\nof 11 cases total , 9 were diagnosed by strain isolation and 2 by pcr and real - time pcr of csf samples ( table ) .\\nstrains isolated from patients 1 , 4 , and 5 became nonviable during storage in the hospital laboratory .\\nthe 6 remaining strains ( from patients 2 , 3 , 7 , and 911 ) were submitted to the chinese cdc along with 16 serotype w strains from close contacts of patients 4 , 6 , and 810 .\\nthus , during 20112012 , a total of 22 strains were submitted to the chinese cdc , where they were confirmed as n. meningitidis serogroup w by slide agglutination with specific antiserum ( remel , lenexa , ks , usa ) .\\nin addition , csf samples from patients 1 , 46 , and 8 were submitted and confirmed positive for n. meningitidis serogroup w by pcr and real - time pcr . *\\nthe 22 serogroup w strains from 20112012 were analyzed by pfge ; for comparison , 3 strains isolated from patients during 20062008 were also analyzed .\\nfive strains associated with patient 9 and 1 strain isolated from a close contact of patient 4 had pfge patterns that differed by 1 and 2 bands , respectively , indicating &gt; 94% similarity with the dominant pattern ( figure 1 ) .\\npfge patterns for the 3 isolates from 20062008 exhibited &lt; 90% similarity with those for isolates from 20112012 , differing by 47 bands .\\nall 22 isolates and 5 csf samples from 20112012 were identified as sequence type ( st ) 11 and pora type p1.5,2 , identical to the genotype of serotype w isolates associated with outbreaks reported in saudi arabia in 2000 and 2001 ( 4,5 ) and burkina faso in 2002 ( 6 ) , sporadic cases in other countries ( 79 ) , and the 3 cases identified in china during 20062008 ( 2 ) .\\npfge patterns for 22 neisseria meningitidis serogroup w strains ( 6 from reported patients , 16 from close contacts ) isolated during 20112012 and 3 isolated during 20062008 , china .\\nall isolates were sequence type 11 ( determined by multilocus sequence typing ) and pora type p1.5,2 .\\nof the 11 patients with cases reported during 20112012 , 4 resided in guangxi province , 2 in guangdong province , and 1 each in jiangsu , zhejiang , anhui , henan , and hunan provinces ( technical appendix ) .\\nthe median age of patients was 20 years ( range 346 ) , 9 ( 81.8% ) were male , and all denied recent foreign travel .\\nthe epidemiologic investigation did not identify any common exposures , social settings , or other connections among the patients .\\nclose contacts of all 11 patients were investigated , and no additional n. meningitidis infections were detected . of the 11 reported cases , 5 occurred in or were associated with laibin city , guangxi province : patients 1 , 4 , and 5 sought care in laibin city ; patient 3 sought care in zhejiang province on april 20 , 2012 , after having traveled to zhejiang province from laibin city on march 26 ; and patient 8 sought care in fangchenggang city , guangxi province , 10 days after a close contact ( partner ) had traveled to laibin city ( technical appendix ) . the partner of patient 8 was subsequently tested and identified as a carrier of st11 serogroup w n. meningitidis .\\na survey of n. meningitidis carriage was conducted among the healthy population of laibin city in september 2011 .\\na total of 1,311 persons 145 years of age were investigated , of whom 8.54% ( 112/1,311 persons ) were positive for n. meningitidis carriage .\\nage groups and percentages of infected persons in each age group were 16 years ( 1.4% ) , 712 years ( 6.0% ) , 1315 years ( 6.7% ) , 1620 years ( 18.5% ) , and 2145 years ( 1.0% ) .\\nthe serogroup for each strain was determined by use of slide agglutination and polyclonal antisera and pcr methods .\\nof the 112 n. meningitidis  positive samples , 20 ( 17.9% ) were st11 serogroup w , and of those 20 samples , 2 , 4 , and 14 were from persons 712 , 1315 , and 1620 years of age , respectively .\\nall 20 strains exhibited indistinguishable pfge patterns that matched the dominant pattern of the disease - associated strains .\\nthe carriage rate of st11 serogroup w n. meningitidis reached 5.5% ( 11/200 ) among 200 students ( 1620 years of age ) in 1 school . since 2003 , the annual incidence of meningococcal disease in china has stayed below 0.2 cases/100,000 population .\\nsurveillance data in china suggest a historical trend for seasonal peaks of meningococcal disease during february  april .\\nthis peak season corresponds with the spring dry season in china , a time when tourists are most likely to visit the country , especially southern china . among the 45 cases of meningococcal disease confirmed during 20112012 by meningococcal etiology and pcr methods , 11 ( 24.4% )\\nwere caused by serogroup w n. meningitidis ( figure 2 ) ; 8 of these 11 cases occurred during february  april .\\nthe 3 cases reported during 20062008 occurred during may , june , and october , respectively .\\nlaboratory - confirmed cases of meningococcal disease , by neisseria meningitidis serogroup and year of symptom onset , china , 20052012 .\\nthe incidence of serogroup w infections reported during february 2011june 2012 represents a marked increase over that reported during 20052010 .\\nthe emergence and spread of a new n. meningitidis serogroup in a region presents a challenge for the prevention and control of meningococcal disease , especially if vaccines used in the region do not cover all serogroups .\\nst7 serogroup a and st4821 serogroup c n. meningitidis strains were identified as the 2 dominant lineages circulating in china during 20032008 , causing &gt; 90% of meningococcal disease cases ( 1 ) .\\nmeningococcal polysaccharide vaccines a and c have been used in china for routine immunization since the outbreak of n. meningitidis serogroup c during 20032004 . in some african countries ,\\nrepeated vaccination against n. meningitidis serogroups a and c is thought to have led to a selective increase in the incidence of meningococci of other serogroups , thereby resulting in a changed profile of meningococcal disease ( 1012 ) . therefore ,\\nmeningococcal disease caused by n. meningitidis strains that belong to serogroups other than a and c , especially those that belong to hyperinvasive lineages , appears to be an emerging problem in china .  \\nthe 11 cases of meningococcal disease caused by st11 serogroup w n. meningitidis strains described here had successively emerged in southeastern china ; furthermore , st11 serogroup w meningococci were isolated from close contacts of the patients and from healthy carriers .\\nthese observations suggest the possible establishment and spread of a clonal complex of serogroup w meningococci in southeastern china . carriage and transmission of this strain have led to the emergence of st11 serogroup w organisms as a cause of endemic meningococcal disease .\\nfurther epidemiologic and microbiological surveillance is needed for monitoring of meningococcal diseases caused by serogroup w in southeastern china and preventing the spread of this clone to other regions .\\nfigure showing distribution of 11 serogroup w meningococcal disease cases identified in china during february 2011june 2012 .</td>\n      <td>during february 2011june 2012 , invasive infection with neisseria meningitidis serogroup w was identified in 11 persons in southeastern china . \\n all isolates tested had matching or near - matching pulsed - field gel electrophoresis patterns and belonged to multilocus sequence type 11 . \\n the epidemiologic investigation suggested recent transmission of this clonal complex in southeastern china .</td>\n      <td>The Study\\nConclusions\\nNone</td>\n    </tr>\n  </tbody>\n</table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1682374332230
        }
      },
      "id": "ed1be9d6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import autotokenizer, from long-text transformer on huggingface"
      ],
      "metadata": {},
      "id": "f36c031f"
    },
    {
      "cell_type": "code",
      "source": [
        "# for EDA we use  \"smaller\" LED checkpoint \"allenai/led-base-16384\". Better performance can however be attained by finetuning \"allenai/led-large-16384\" at the cost of a higher required GPU RAM."
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1682374372278
        }
      },
      "id": "d73359d0"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1682374476907
        }
      },
      "id": "7af69e18"
    },
    {
      "cell_type": "code",
      "source": [
        "#we start with longformer: LongformerTokenizer (AllenAI Longformer model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8237ec1263a4654b500f0d035d1e845"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faaf80b7608c4215a29626d6fed0ec57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20869c2f8c32493ea4a39289dc28d08c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62dfed640e4d4bc58ec0251e0ae07906"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29e0c4c80ccc4fe1b6c25f25977953b5"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1682374565778
        }
      },
      "id": "6a831eb8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pubmed's input data has a median token length of 2715 with the 90%-ile token length being 6101. The output data has a media token length of 171 with the 90%-ile token length being 352.\n",
        "(cited from Big Bird: Transformers for Longer Sequences paper : https://arxiv.org/pdf/2007.14062.pdf)\n",
        "\n",
        "Thus, we set the maximum input length to 8192 and the maximum output length to 512 to ensure that the model can attend to almost all input tokens is able to generate up to a large enough number of output tokens.\n",
        "\n",
        "In this notebook, we are only able to train on batch_size=2 to prevent out-of-memory errors."
      ],
      "metadata": {},
      "id": "31f5d833"
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 8192\n",
        "max_output_length = 512\n",
        "batch_size = 2"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1682374566175
        }
      },
      "id": "5fc2ce85"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's write down the input data processing function that will be used to map each data sample to the correct model format. As explained earlier article represents here our input data and abstract is the target data. The datasamples are thus tokenized up to the respective maximum lengths of 8192 and 512.\n",
        "\n",
        "In addition to the usual attention_mask, LED can make use of an additional global_attention_mask defining which input tokens are attended globally and which are attended only locally, just as it's the case of Longformer. For more information on Longformer's self-attention, please take a look at the corresponding docs. For summarization, we follow recommendations of the paper and use global attention only for the very first token. Finally, we make sure that no loss is computed on padded tokens by setting their index to -100."
      ],
      "metadata": {},
      "id": "bc86e40c"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_to_model_inputs(batch):\n",
        "    # tokenize the inputs and labels\n",
        "    #Returns a dictionary containing the encoded sequence or sequence pair \n",
        "    # and additional information: the mask for sequence classification and \n",
        "    # the overflowing elements if a max_length is specified.\n",
        "    inputs = tokenizer(\n",
        "        batch[\"article\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length,\n",
        "    )\n",
        "    outputs = tokenizer(\n",
        "        batch[\"abstract\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_output_length,\n",
        "    )\n",
        "\n",
        "    #Hugingface tokenizer returns the attention mask and input ids.\n",
        "    #     input_ids: list of token ids to be fed to a model\n",
        "    # token_type_ids: list of token type ids to be fed to a model\n",
        "    # attention_mask: list of indices specifying which tokens should be attended to by the model\n",
        "    # overflowing_tokens: list of overflowing tokens sequences if a max length is specified and return_overflowing_tokens=True.\n",
        "    # special_tokens_mask: if adding special tokens, this is a list of [0, 1], with 0 specifying special added tokens and 1 specifying sequence tokens.\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "\n",
        "    # create 0 global_attention_mask lists\n",
        "    # len(batch[\"input_ids\"]) = minibatch size ( or batch_size)\n",
        "    # len(batch[\"input_ids\"][0]) = max_input_length\n",
        "    # in effect a 2-d Python List of dimension (batch_size x max_input_length)    \n",
        "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
        "        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
        "    ]\n",
        "\n",
        "    # since above lists are references, the following line changes the 0 index for all samples\n",
        "    batch[\"global_attention_mask\"][0][0] = 1\n",
        "    batch[\"labels\"] = outputs.input_ids\n",
        "\n",
        "    # We have to make sure that the PAD token is ignored. current pad_token_id is = 1 in this model\n",
        "    # batch labels is the output tokenizer dimension (batch_size x max_output_length)\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "        for labels in batch[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    return batch"
      ],
      "outputs": [],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1682374649376
        }
      },
      "id": "a19855f3"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "e015e67a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downsample for EDA and development!"
      ],
      "metadata": {},
      "id": "8511d432"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.select(range(250))\n",
        "# val_dataset = val_dataset.select(range(25))"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1682374655220
        }
      },
      "id": "39695dda"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"article\", \"abstract\", \"section_names\"],\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/250 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "711a4b2849214741ac8bd7bb8c34ab85"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1682374661434
        }
      },
      "id": "2bfbc703"
    },
    {
      "cell_type": "code",
      "source": [
        "# val_dataset = val_dataset.map(\n",
        "#     process_data_to_model_inputs,\n",
        "#     batched=True,\n",
        "#     batch_size=batch_size,\n",
        "#     remove_columns=[\"article\", \"abstract\", \"section_names\"],\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "f73027d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset to Torch format"
      ],
      "metadata": {},
      "id": "c7b57a73"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
        ")\n",
        "# val_dataset.set_format(\n",
        "#     type=\"torch\",\n",
        "#     columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
        "# )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1682374671022
        }
      },
      "id": "8fee9683"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model via the AutoModelForSeq2SeqLM class."
      ],
      "metadata": {},
      "id": "c04ae011"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1682374671694
        }
      },
      "id": "ea8afbd9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tradeoff just in EDA: We've decided to stick to the smaller model \"allenai/led-base-16384\" for the sake of this notebook. In addition, we directly enable gradient checkpointing and disable the caching mechanism to save memory."
      ],
      "metadata": {},
      "id": "2417d87c"
    },
    {
      "cell_type": "code",
      "source": [
        "led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\",\n",
        "                                            gradient_checkpointing=True,\n",
        "                                            use_cache=False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/648M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d213604638324d7a829aa4ba7bd25dca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d5548a3a6c04d90bcadfa4e0e3fd4bf"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1682374709946
        }
      },
      "id": "245d09c7"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "f049e0d3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training: we need to evaluate the model on Rouge\n",
        "\n",
        "ROUGE score: https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html\n",
        "Per Wikipedia: Recall-Oriented Understudy for Gisting Evaluation. It's a set of metrics and a software package used for evaluating automatic summarization and machine translation software in natural language processing. The metrics compare an automatically produced summary or translation against a reference or a set of references (human-produced) summary or translation.\n",
        "\n",
        "ROUGE is currently the most well used summarization metrics (as proposed in Milestone #1) that we will use.\n",
        "\n",
        "Setting fitting generation parameters for loss calculation.\n",
        "\n",
        "- beam search with a small beam of just 2 to save memory. \n",
        "- force the model to generate at least 100 tokens, but no more than 512.\n",
        "- setting earlyt stopping and no_repeat_ngram to prevent spurious repetition"
      ],
      "metadata": {},
      "id": "05528cb3"
    },
    {
      "cell_type": "code",
      "source": [
        "# set generate hyperparameters\n",
        "led.config.num_beams = 2\n",
        "led.config.max_length = 512\n",
        "led.config.min_length = 100\n",
        "led.config.length_penalty = 2.0\n",
        "led.config.early_stopping = True\n",
        "led.config.no_repeat_ngram_size = 3"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1682374710317
        }
      },
      "id": "a45c8f0a"
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = load_metric(\"rouge\")"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1682374710688
        }
      },
      "id": "8e8024d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The compute metrics function expects the generated output = pred.predictions\n",
        "and true label = pred.label_ids.\n",
        "\n",
        "We need to decode the tokens then calculate ROUGE"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "aff7673c"
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    # true labels\n",
        "    labels_ids = pred.label_ids\n",
        "    # predicted labels\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    # decode in batch from tokens into string both true string and predicted string\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    # compute rouge score\n",
        "    rouge_output = rouge.compute(\n",
        "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
        "    )[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1682375341176
        }
      },
      "id": "1ad7b7d4"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1682375100507
        }
      },
      "id": "86b3e05b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq2SeqTrainer : we eventually want to turn on predict_with_generate=True to inspect. Right now I'm turning it off to save RAM.\n",
        "\n",
        "Current batch size is set to 2, then I do gradient_accumulation_steps=4 to batch the gradient, to conserve RAM. Effective batch size becomes (batch_size = 2) * (grad_accum_steps = 4) = 8"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "656a6b5f-d25f-4229-b9a2-d35647b201db"
    },
    {
      "cell_type": "code",
      "source": [
        "#MKIMMINS: IF CUDA\n",
        "# enabled floating point precision : fp16 apex training\n",
        "\n",
        "#IF NO CUDA ON MPI, DO NOT USE FP16\n",
        "CUDA = False\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    fp16=CUDA,\n",
        "    output_dir=\"./\",\n",
        "    logging_steps=5,\n",
        "    eval_steps=10,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682375321126
        }
      },
      "id": "fe9822ba-a138-4b28-9a73-63ff51addf95"
    },
    {
      "cell_type": "code",
      "source": [
        "#MKIMMINS VAL DATASET TURNED OFF FOR SPEED\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=led,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset\n",
        "    # ,\n",
        "    # eval_dataset=val_dataset,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682375357284
        }
      },
      "id": "a9a7e2af-1a57-42a5-a755-741d7ea65c6f"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a LEDTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        }
      ],
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1682375440179
        }
      },
      "id": "7b168ca8-ba45-4c0b-bcd9-fc5805b4e26e"
    },
    {
      "cell_type": "code",
      "source": [
        "led.save(\"mkimmins_fine_tune_10\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "c90e5482-2717-4234-b00c-295881de6eda"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "92984924-6238-45c3-bd1f-2feb38a2547e"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "cd06fbb8"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "a4dedef4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}